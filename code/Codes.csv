Title,Abstract
Intelligible models for healthcare: Predicting pneumonia risk and hospital 30-day readmission,"This article discusses the development of intelligible machine learning models for healthcare applications. The focus is on predicting the risk of pneumonia and the likelihood of hospital readmission within 30 days. The authors emphasize the need for models that are not only accurate but also interpretable in the healthcare domain, with practical implications for patient care and outcomes"
Global reconstruction of language models with linguistic rules ¨C Explainable AI for online consumer reviews,"This paper presents research on the global reconstruction of language models with the use of linguistic rules, focusing on the application of Explainable AI (XAI) for analyzing online consumer reviews. The research aims to enhance the interpretability and transparency of language models in the context of online product reviews"
A unified approach to interpreting model predictions,"This article proposes a unified approach to interpreting model predictions. The authors aim to provide a systematic and generalizable method for explaining machine learning model predictions, contributing to the field of interpretable machine learning"
Local Interpretable Model-Agnostic Explanations for Black Box Models,"This paper introduces a local interpretable model-agnostic explanation (LIME) framework for explaining predictions of black-box models. LIME is designed to provide interpretable explanations for model decisions, making it applicable to various machine learning models"
Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead,This article argues against the practice of explaining black box machine learning models in high-stakes decision-making scenarios and advocates for the use of interpretable models instead. The author emphasizes the need for transparency and interpretability in critical decision processes
